\section*{MATH1231/1241 Algebra S2 2007 Test 1 Version 1B}
\begin{enumerate}
    % Q1: subspace theorem
    \item
        \begin{enumerate}
            \item 
                We have $S = \{\v{x} \in \R^4 ~|~ x_1 - 5x_3 = 2x_4\}$.

                \begin{itemize}
                    \item
                        Clearly, $\v{0} \in S$:
                        $$0 - 5(0) = 2(0)$$
                        and so $S$ is not empty.

                    \item
                        Suppose $\x = (x_1, \dots, x_4)^T,~
                        \y = (y_1, \dots, y_4)^T \in S$. Then,
                        \begin{align*}
                            &\left\{\begin{matrix}
                                x_1 - 5x_3 = 2x_4 \\
                                y_1 - 5y_3 = 2y_4
                            \end{matrix}\right. \\
                            \implies
                            &(x_1 + y_1) - 5(x_3 + y_3) = 2(x_4 + y_4) \\
                            \implies
                            &(\x + \y) \in S
                        \end{align*}

                        And so $S$ is closed under vector addition.

                    \item
                        Suppose $\x = (x_1, \dots, x_4)^T \in S,~ \lambda \in \R$.
                        Then,
                        \begin{align*}
                            x_1 - 5x_3 &= 2x_4 \\
                            (\lambda)x_1 - (5\lambda)x_3 &= (2\lambda)x_4 \\
                            (\lambda x_1) - 5(\lambda x_3) &= 2(\lambda x_4) \\
                            \implies
                            \lambda \x \in S
                        \end{align*}

                        And so $S$ is closed under scalar multiplication.
                \end{itemize}

                It follows that set $S$ is a subspace of the vector
                space $\R^4$ by the Subspace Theorem.

            \item
                One such vector is $\x = (0, 1, 0, 0)^T$.
                Clearly, $\x \in S$, and $\x \neq \v{0}$.
        \end{enumerate}

    % Q2: polynomial space
    \item
        Let $p \in P_2$, with $p(t) = a + bt + ct^2$.

        Now, $S = \{p_1, \dots, p_4\}$ is a spanning set for $\P_2$ if
        and only if there exist $\lambda_1, \dots, \lambda_4 \in \R$
        such that, for all $t$, $p(t) = \lambda_1 p_1(t) + \dots
        \lambda_4 p_4(t)$.

        Expanding and equating coefficients, we get a system of linear
        equations
        \begin{align*}
            \lambda_1 + 2\lambda_2 - \lambda_3 &= a \\
            -\lambda_1 - \lambda_2 + 5\lambda_3 + \lambda_4 &= b \\
            2\lambda_1 + 3\lambda_2 - 5\lambda_3 - 2\lambda_4 &= c
        \end{align*}
        which has a solution if and only if $S$ is a spanning set for
        $\P_2$.

        Writing it in augmented matrix form and row-reducing, we obtain:

        \begin{math}
            \begin{amatrix}{4}
                1   &   2   & -1    & 0     & a \\
                -1  &   -1  & 5     & 1     & b \\
                2   &   3   & -5    & -2    & c \\
            \end{amatrix}
            \xrightarrow[R3 = R3 - 2R1]{R2 = R1 + R2}
            \begin{amatrix}{4}
                1   &   2   & -1    & 0     & a \\
                0   &   1   & 4     & 1     & a+b \\
                0   &   -1  & -3    & -2    & c-2a \\
            \end{amatrix}
            \xrightarrow{R3 = R2 + R3} \\[5mm]
            \begin{amatrix}{4}
                1   &   2   & -1    & 0     & a \\
                0   &   1   & 4     & 1     & a+b \\
                0   &   0   & 1     & -1    & c-a+b \\
            \end{amatrix} \\
        \end{math}

        The right-hand column is always non-leading, and thus the system
        always has a solution.

        It follows that $S$ is a spanning set for $P_2$.

    \item
        The given vectors are linearly independent if and only if
        the system of equations represented by the following matrix has
        only the trivial zero solution:
        $$
            \begin{amatrix}{3}
                1  & 2 & 1 & 0 \\
                4  & 5 & 3 & 0 \\
                -2 & 5 & 1 & 0 \\
            \end{amatrix}
        $$
        Row-reducing:

        \begin{math}
            \xrightarrow[R3 = R3 + 2R1]{R2 = R2 - 4R1}
            \begin{amatrix}{3}
                1 & 2  & 1  & 0 \\
                0 & -3 & -1 & 0 \\
                0 & 9  & 3  & 0 \\
            \end{amatrix}
            \xrightarrow{R3 = R3 + 3R2}
            \begin{amatrix}{3}
                1 & 2  & 1  & 0 \\
                0 & -3 & -1 & 0 \\
                0 & 0  & 0  & 0 \\
            \end{amatrix}
        \end{math}

        REF has only one non-leading column, and therefore
        the system has infinitely many solutions.

        It follows that the given vectors are linearly dependent.
\end{enumerate}
